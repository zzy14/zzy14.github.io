---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a 5th-year PhD student in the Department of Computer Science and Technology at Tsinghua University. I am supervised by Prof. [Zhiyuan Liu](http://nlp.csai.tsinghua.edu.cn/~lzy/index.html). My research interests lie in Pre-trained Models for Natural Language Processing. <strong>I'm currently exploring the job market for new roles.</strong>

<!-- * <strong>Zhengyan Zhang</strong>, Fanchao Qi, Zhiyuan Liu, Qun Liu, Maosong Sun. Know What You Don't Need: Single-Shot Meta-Pruning for Attention Heads. [[arxiv]](https://arxiv.org/abs/2011.03770) -->

<!-- * Yusheng Su, Xu Han, <strong>Zhengyan Zhang</strong>, Peng Li, Zhiyuan Liu, Yankai Lin, Jie Zhou, Maosong Sun. CokeBERT: Contextual Knowledge Selection and Embedding towards Enhanced Pre-Trained Language Models. [[arxiv]](https://arxiv.org/abs/2009.13964) -->

<!-- * Jie Zhou\*, Ganqu Cui\*, <strong>Zhengyan Zhang</strong>\*, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li, Maosong Sun. Graph Neural Networks: A Review of Methods and Applications. [[arxiv]](https://arxiv.org/abs/1812.08434) -->


## Main Publications

\* indicates equal contribution.

* <strong>Zhengyan Zhang</strong>\*, Zhiyuan Zeng\*, Yankai Lin, Huadong Wang, Deming Ye, Chaojun Xiao, et al. Plug-and-Play Knowledge Injection for Pre-trained Language Models. <i>Proceedings of The 61st Annual Meeting of the Association for Computational Linguistics (ACL 2023)</i>. [[arxiv]](https://arxiv.org/pdf/2305.17691.pdf)

* <strong>Zhengyan Zhang</strong>\*, Zhiyuan Zeng\*, Yankai Lin, Chaojun Xiao, Xiaozhi Wang, Xu Han, Zhiyuan Liu, et al. Emergent Modularity in Pre-trained Transformers. <i>Findings of ACL 2023</i>. [[arxiv]](https://arxiv.org/pdf/2305.18390.pdf)

* Chenglei Si\*, <strong>Zhengyan Zhang</strong>\*, Yingfa Chen\*, Xiaozhi Wang, Zhiyuan Liu and Maosong Sun.	READIN: A Chinese Multi-Task Benchmark with Realistic and Diverse Input Noises. <i>Proceedings of The 61st Annual Meeting of the Association for Computational Linguistics (ACL 2023)</i>. [[arxiv]](https://arxiv.org/pdf/2302.07324.pdf)

* Chenglei Si\*, <strong>Zhengyan Zhang</strong>\*, Yingfa Chen\*, Fanchao Qi, Xiaozhi Wang, Zhiyuan Liu, Yasheng Wang, Qun Liu, Maosong Sun. Sub-Character Tokenization for Chinese Pretrained Language Models. <i>Transactions of the Association for Computational Linguistics</i>. [[arxiv]](https://arxiv.org/abs/2106.00400)

* <strong>Zhengyan Zhang</strong>, Baitao Gong, Yingfa Chen, Xu Han, Guoyang Zeng, Weilin Zhao, Yanxu Chen, Zhiyuan Liu, Maosong Sun. BMCook: A Task-agnostic Compression Toolkit for Big Models. <i>Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: System Demonstrations (EMNLP 2022 Demo)</i>. [[pdf]](https://aclanthology.org/2022.emnlp-demos.40.pdf)

* <strong>Zhengyan Zhang</strong>, Yankai Lin, Zhiyuan Liu, Peng Li, Maosong Sun, Jie Zhou. MoEfication: Transformer Feed-forward Layers are Mixtures of Experts. <i>Findings of ACL 2022</i>. [[pdf]](https://aclanthology.org/2022.findings-acl.71.pdf)

* <strong>Zhengyan Zhang</strong>, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng, Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun. CPM: A Large-scale Generative Chinese Pre-trained Language Model. AI Open. [[arxiv]](https://arxiv.org/abs/2012.00413) [[code]](https://github.com/TsinghuaAI/CPM-Generate) [[homepage]](https://cpm.baai.ac.cn/)

* Yuan Yao, Haoxi Zhong, <strong>Zhengyan Zhang</strong>, Xu Han, Xiaozhi Wang, Chaojun Xiao, Guoyang Zeng, Zhiyuan Liu, Maosong Sun. Adversarial Language Games for Advanced Natural Language Intelligence. <i>AAAI Conference on Artifical Intelligence (AAAI 2021)</i>. [[arxiv]](https://arxiv.org/abs/1911.01622)

* Xiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, <strong>Zhengyan Zhang</strong>, Zhiyuan Liu, Juanzi Li, Jian Tang. KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation. <i>Transactions of the Association for Computational Linguistics.</i> [[pdf]](https://bakser.github.io/files/TACL-KEPLER/KEPLER.pdf) [[dataset]](https://deepgraphlearning.github.io/project/wikidata5m)

* Yuxian Gu, <strong>Zhengyan Zhang</strong>, Xiaozhi Wang, Zhiyuan Liu, Maosong Sun. Train No Evil: Selective Masking for Task-guided Pre-training. <i>The Conference on Empirical Methods in Natural Language Processing (EMNLP 2020).</i> [[pdf]](https://www.aclweb.org/anthology/2020.emnlp-main.566.pdf) [[code]](https://github.com/thunlp/SelectiveMasking) (short)

* <strong>Zhengyan Zhang</strong>\*, Xu Han\*, Zhiyuan Liu, Xin Jiang, Maosong Sun, Qun Liu. ERNIE: Enhanced Language Representation with Informative Entities. <i>The 57th Annual Meeting of the Association for Computational Linguistics (ACL 2019).</i> [[arxiv]](https://arxiv.org/abs/1905.07129) [[code]](https://github.com/thunlp/ERNIE)

* <strong>Zhengyan Zhang</strong>, Cheng Yang, Zhiyuan Liu, Maosong Sun, Zhichong Fang, Bo Zhang, Leyu Lin. COSINE: Compressive network embedding on large-scale information networks. <i>IEEE Transactions on Knowledge and Data Engineering. (TKDE)</i> [[pdf]](https://ieeexplore.ieee.org/abstract/document/9222322/)

* Cunchao Tu, <strong>Zhengyan Zhang</strong>, Zhiyuan Liu, Maosong Sun. TransNet: Translation-Based Network Representation Learning for Social Relation Extraction. <i>International Joint Conference on Artificial Intelligence. (IJCAI 2017)</i> [[pdf]](http://nlp.csai.tsinghua.edu.cn/~lzy/publications/ijcai2017_transnet.pdf) [[code]](https://github.com/thunlp/TransNet)

* Cunchao Tu, Xiangkai Zeng, Hao Wang, <strong>Zhengyan Zhang</strong>, Zhiyuan Liu, Maosong Sun, Bo Zhang, Leyu Lin. A Unified Framework for Community Detection and Network Representation Learning. <i>IEEE Transactions on Knowledge and Data Engineering. (TKDE)</i> [[pdf]](https://arxiv.org/pdf/1611.06645.pdf)
